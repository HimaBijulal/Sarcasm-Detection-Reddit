{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1010826 entries, 0 to 1010825\n",
      "Data columns (total 2 columns):\n",
      "comment    1010826 non-null object\n",
      "label      1010826 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 15.4+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import os \n",
    "import pandas as pd \n",
    "import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "#print how many rows and columns are there in the csv file\n",
    "df = pd.read_csv('train-balanced-sarcasm.csv')\n",
    "\n",
    "\n",
    "df_useful_x = df[['comment','label']]\n",
    "df_useful_y = df[['label']]\n",
    "df_useful_x['comment'] = df_useful_x['comment'].astype('str')\n",
    "\n",
    "df_useful_x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "      <th>pre_clean_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NC and NH.</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>This meme isn't funny none of the \"new york ni...</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>I could use one of those tools.</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010821</td>\n",
       "      <td>I'm sure that Iran and N. Korea have the techn...</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010822</td>\n",
       "      <td>whatever you do, don't vote green!</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010823</td>\n",
       "      <td>Perhaps this is an atheist conspiracy to make ...</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010824</td>\n",
       "      <td>The Slavs got their own country - it is called...</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010825</td>\n",
       "      <td>values, as in capitalism .. there is good mone...</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1010826 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   comment  label  \\\n",
       "0                                               NC and NH.      0   \n",
       "1        You do know west teams play against west teams...      0   \n",
       "2        They were underdogs earlier today, but since G...      0   \n",
       "3        This meme isn't funny none of the \"new york ni...      0   \n",
       "4                          I could use one of those tools.      0   \n",
       "...                                                    ...    ...   \n",
       "1010821  I'm sure that Iran and N. Korea have the techn...      1   \n",
       "1010822                 whatever you do, don't vote green!      1   \n",
       "1010823  Perhaps this is an atheist conspiracy to make ...      1   \n",
       "1010824  The Slavs got their own country - it is called...      1   \n",
       "1010825  values, as in capitalism .. there is good mone...      1   \n",
       "\n",
       "         pre_clean_len  \n",
       "0                   10  \n",
       "1                   74  \n",
       "2                  121  \n",
       "3                   60  \n",
       "4                   31  \n",
       "...                ...  \n",
       "1010821             92  \n",
       "1010822             34  \n",
       "1010823             66  \n",
       "1010824             53  \n",
       "1010825             72  \n",
       "\n",
       "[1010826 rows x 3 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_useful_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.count of                                                    comment  label  \\\n",
       "0                                               NC and NH.      0   \n",
       "1        You do know west teams play against west teams...      0   \n",
       "2        They were underdogs earlier today, but since G...      0   \n",
       "3        This meme isn't funny none of the \"new york ni...      0   \n",
       "4                          I could use one of those tools.      0   \n",
       "...                                                    ...    ...   \n",
       "1010821  I'm sure that Iran and N. Korea have the techn...      1   \n",
       "1010822                 whatever you do, don't vote green!      1   \n",
       "1010823  Perhaps this is an atheist conspiracy to make ...      1   \n",
       "1010824  The Slavs got their own country - it is called...      1   \n",
       "1010825  values, as in capitalism .. there is good mone...      1   \n",
       "\n",
       "         pre_clean_len  \n",
       "0                   10  \n",
       "1                   74  \n",
       "2                  121  \n",
       "3                   60  \n",
       "4                   31  \n",
       "...                ...  \n",
       "1010821             92  \n",
       "1010822             34  \n",
       "1010823             66  \n",
       "1010824             53  \n",
       "1010825             72  \n",
       "\n",
       "[1010826 rows x 3 columns]>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_useful_x['pre_clean_len'] = [len(t) for t in df_useful_x.comment]\n",
    "df_useful_x\n",
    "\n",
    "df_useful_x[df_useful_x.pre_clean_len > 140].head(10)\n",
    "df_useful_x.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the comments...\n",
      "\n",
      "comments 10000 of 1010826 has been processed\n",
      "comments 20000 of 1010826 has been processed\n",
      "comments 30000 of 1010826 has been processed\n",
      "comments 40000 of 1010826 has been processed\n",
      "comments 50000 of 1010826 has been processed\n",
      "comments 60000 of 1010826 has been processed\n",
      "comments 70000 of 1010826 has been processed\n",
      "comments 80000 of 1010826 has been processed\n",
      "comments 90000 of 1010826 has been processed\n",
      "comments 100000 of 1010826 has been processed\n",
      "comments 110000 of 1010826 has been processed\n",
      "comments 120000 of 1010826 has been processed\n",
      "comments 130000 of 1010826 has been processed\n",
      "comments 140000 of 1010826 has been processed\n",
      "comments 150000 of 1010826 has been processed\n",
      "comments 160000 of 1010826 has been processed\n",
      "comments 170000 of 1010826 has been processed\n",
      "comments 180000 of 1010826 has been processed\n",
      "comments 190000 of 1010826 has been processed\n",
      "comments 200000 of 1010826 has been processed\n",
      "comments 210000 of 1010826 has been processed\n",
      "comments 220000 of 1010826 has been processed\n",
      "comments 230000 of 1010826 has been processed\n",
      "comments 240000 of 1010826 has been processed\n",
      "comments 250000 of 1010826 has been processed\n",
      "comments 260000 of 1010826 has been processed\n",
      "comments 270000 of 1010826 has been processed\n",
      "comments 280000 of 1010826 has been processed\n",
      "comments 290000 of 1010826 has been processed\n",
      "comments 300000 of 1010826 has been processed\n",
      "comments 310000 of 1010826 has been processed\n",
      "comments 320000 of 1010826 has been processed\n",
      "comments 330000 of 1010826 has been processed\n",
      "comments 340000 of 1010826 has been processed\n",
      "comments 350000 of 1010826 has been processed\n",
      "comments 360000 of 1010826 has been processed\n",
      "comments 370000 of 1010826 has been processed\n",
      "comments 380000 of 1010826 has been processed\n",
      "comments 390000 of 1010826 has been processed\n",
      "comments 400000 of 1010826 has been processed\n",
      "comments 410000 of 1010826 has been processed\n",
      "comments 420000 of 1010826 has been processed\n",
      "comments 430000 of 1010826 has been processed\n",
      "comments 440000 of 1010826 has been processed\n",
      "comments 450000 of 1010826 has been processed\n",
      "comments 460000 of 1010826 has been processed\n",
      "comments 470000 of 1010826 has been processed\n",
      "comments 480000 of 1010826 has been processed\n",
      "comments 490000 of 1010826 has been processed\n",
      "comments 500000 of 1010826 has been processed\n",
      "comments 510000 of 1010826 has been processed\n",
      "comments 520000 of 1010826 has been processed\n",
      "comments 530000 of 1010826 has been processed\n",
      "comments 540000 of 1010826 has been processed\n",
      "comments 550000 of 1010826 has been processed\n",
      "comments 560000 of 1010826 has been processed\n",
      "comments 570000 of 1010826 has been processed\n",
      "comments 580000 of 1010826 has been processed\n",
      "comments 590000 of 1010826 has been processed\n",
      "comments 600000 of 1010826 has been processed\n",
      "comments 610000 of 1010826 has been processed\n",
      "comments 620000 of 1010826 has been processed\n",
      "comments 630000 of 1010826 has been processed\n",
      "comments 640000 of 1010826 has been processed\n",
      "comments 650000 of 1010826 has been processed\n",
      "comments 660000 of 1010826 has been processed\n",
      "comments 670000 of 1010826 has been processed\n",
      "comments 680000 of 1010826 has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/bs4/__init__.py:294: UserWarning: \"b'..'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comments 690000 of 1010826 has been processed\n",
      "comments 700000 of 1010826 has been processed\n",
      "comments 710000 of 1010826 has been processed\n",
      "comments 720000 of 1010826 has been processed\n",
      "comments 730000 of 1010826 has been processed\n",
      "comments 740000 of 1010826 has been processed\n",
      "comments 750000 of 1010826 has been processed\n",
      "comments 760000 of 1010826 has been processed\n",
      "comments 770000 of 1010826 has been processed\n",
      "comments 780000 of 1010826 has been processed\n",
      "comments 790000 of 1010826 has been processed\n",
      "comments 800000 of 1010826 has been processed\n",
      "comments 810000 of 1010826 has been processed\n",
      "comments 820000 of 1010826 has been processed\n",
      "comments 830000 of 1010826 has been processed\n",
      "comments 840000 of 1010826 has been processed\n",
      "comments 850000 of 1010826 has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/bs4/__init__.py:357: UserWarning: \"http://localhost:88/emblem-bot/index.php\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comments 860000 of 1010826 has been processed\n",
      "comments 870000 of 1010826 has been processed\n",
      "comments 880000 of 1010826 has been processed\n",
      "comments 890000 of 1010826 has been processed\n",
      "comments 900000 of 1010826 has been processed\n",
      "comments 910000 of 1010826 has been processed\n",
      "comments 920000 of 1010826 has been processed\n",
      "comments 930000 of 1010826 has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/bs4/__init__.py:357: UserWarning: \"http://last.word/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comments 940000 of 1010826 has been processed\n",
      "comments 950000 of 1010826 has been processed\n",
      "comments 960000 of 1010826 has been processed\n",
      "comments 970000 of 1010826 has been processed\n",
      "comments 980000 of 1010826 has been processed\n",
      "comments 990000 of 1010826 has been processed\n",
      "comments 1000000 of 1010826 has been processed\n",
      "comments 1010000 of 1010826 has been processed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>nc and nh</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>you do know west teams play against west teams...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>they were underdogs earlier today but since gr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>this meme isn t funny none of the new york nig...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>i could use one of those tools</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  sentiment\n",
       "0                                          nc and nh          0\n",
       "1  you do know west teams play against west teams...          0\n",
       "2  they were underdogs earlier today but since gr...          0\n",
       "3  this meme isn t funny none of the new york nig...          0\n",
       "4                     i could use one of those tools          0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tok = WordPunctTokenizer()\n",
    "pat1 = r'@[A-Za-z0-9]+'\n",
    "pat2 = r'https?://[A-Za-z0-9./]+'\n",
    "combined_pat = r'|'.join((pat1, pat2))\n",
    "\n",
    "def text_cleaner(text):\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    souped = soup.get_text()\n",
    "    stripped = re.sub(combined_pat, '', souped)\n",
    "    try:\n",
    "        clean = stripped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "    except:\n",
    "        clean = stripped\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", clean)\n",
    "    lower_case = letters_only.lower()\n",
    "    # During the letters_only process two lines above, it has created unnecessay white spaces,\n",
    "    # I will tokenize and join together to remove unneccessary white spaces\n",
    "    words = tok.tokenize(lower_case)\n",
    "    return (\" \".join(words)).strip()\n",
    "\n",
    "\n",
    "\n",
    "nums = [0,1010826]\n",
    "print (\"Cleaning and parsing the comments...\\n\")\n",
    "clean_comment_texts = []\n",
    "for i in range(nums[0],nums[1]):\n",
    "    if( (i+1)%10000 == 0 ):\n",
    "        print (\"comments %d of %d has been processed\" % ( i+1, nums[1] ))                                                                    \n",
    "    clean_comment_texts.append(text_cleaner(df_useful_x['comment'][i]))\n",
    "    \n",
    "clean_df = pd.DataFrame(clean_comment_texts,columns=['comment'])\n",
    "clean_df['sentiment'] = df_useful_x.label\n",
    "clean_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>nc and nh</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>you do know west teams play against west teams...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>they were underdogs earlier today but since gr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>this meme isn t funny none of the new york nig...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>i could use one of those tools</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010821</td>\n",
       "      <td>i m sure that iran and n korea have the techno...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010822</td>\n",
       "      <td>whatever you do don t vote green</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010823</td>\n",
       "      <td>perhaps this is an atheist conspiracy to make ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010824</td>\n",
       "      <td>the slavs got their own country it is called k...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010825</td>\n",
       "      <td>values as in capitalism there is good money in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1010826 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   comment  sentiment\n",
       "0                                                nc and nh          0\n",
       "1        you do know west teams play against west teams...          0\n",
       "2        they were underdogs earlier today but since gr...          0\n",
       "3        this meme isn t funny none of the new york nig...          0\n",
       "4                           i could use one of those tools          0\n",
       "...                                                    ...        ...\n",
       "1010821  i m sure that iran and n korea have the techno...          1\n",
       "1010822                   whatever you do don t vote green          1\n",
       "1010823  perhaps this is an atheist conspiracy to make ...          1\n",
       "1010824  the slavs got their own country it is called k...          1\n",
       "1010825  values as in capitalism there is good money in...          1\n",
       "\n",
       "[1010826 rows x 2 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['label', 'comment', 'author', 'subreddit', 'score', 'ups', 'downs',\n",
      "       'date', 'created_utc', 'parent_comment'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#show the columns to see which ones we would need to use, and make a subdataframe with columns we need\n",
    "\n",
    "# convert each dataframe into 2D numpy arrays\n",
    "x= df_useful_x.to_numpy()\n",
    "y= df_useful_y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['NC and NH.'],\n",
       "       ['You do know west teams play against west teams more than east teams right?'],\n",
       "       [\"They were underdogs earlier today, but since Gronk's announcement this afternoon, the Vegas line has moved to patriots -1\"],\n",
       "       ...,\n",
       "       ['Perhaps this is an atheist conspiracy to make Christians look bad?'],\n",
       "       ['The Slavs got their own country - it is called Kosovo'],\n",
       "       ['values, as in capitalism .. there is good money in imprisoning people ..']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test, Y_train, Y_test = train_test_split(x,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Looks more deformed than half elephant..'],\n",
       "       [\"If you want our president to be killed you are not a patriot, you're a fucking traitor.\"],\n",
       "       ['\"Acceptance\"'],\n",
       "       ...,\n",
       "       ['agreed , This vid shows how much better this guy is then kennyS at his best'],\n",
       "       ['Hang ingat hang mat salleh ka nyanyi lagu ongputeh?'],\n",
       "       [\"From what I've read, inferno isn't as hard as bliz made it out to be, they just have not-hardcore testers.\"]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Das racist'],\n",
       "       ['Ugh, people are always complaining about us 1%ers.'],\n",
       "       ['But using the lightning port means that there will have to be a DAC in the adapter (not sure about an amp), and it will probably be low quality.'],\n",
       "       ...,\n",
       "       ['Da buon padre fa la cosa giusta e avvisalo, o quantomeno insegnagli a cucinare'],\n",
       "       [\"Why don't you let the parent do the parenting?\"],\n",
       "       ['I really hope you forgot to put']], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       ...,\n",
       "       [1],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Dataset Shape:\n",
      "X_train: (808660, 1)\n",
      "Y_train: (808660, 1)\n",
      "X_test:  (202166, 1)\n",
      "Y_test:  (202166, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Reddit Dataset Shape:')\n",
    "print('X_train: ' + str(X_train.shape))\n",
    "print('Y_train: ' + str(Y_train.shape))\n",
    "print('X_test:  '  + str(X_test.shape))\n",
    "print('Y_test:  '  + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: \"If you want our president to be killed you are not a patriot, you're a fucking traitor.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-f7bdb2cfb9c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# pad upto max_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/keras_preprocessing/sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;31m# check `trunc` has expected shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mtrunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msample_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             raise ValueError('Shape of sample %s of sequence at position %s '\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: \"If you want our president to be killed you are not a patriot, you're a fucking traitor.\""
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "max_words=500\n",
    "X_train = X_train[1:200]\n",
    "Y_train = Y_train[1:200]\n",
    "\n",
    "X_test = X_test[1:200]\n",
    "Y_test = Y_test[1:200]\n",
    "\n",
    "# pad upto max_words\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
